{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1qj559L3-B234xok_yWtlnFH34sl8PyUR",
      "authorship_tag": "ABX9TyP2V1x6HWN7DvS6FjWg/pd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vranade-cyber/11785_Part-2/blob/main/DL1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl5XtOW93zTa"
      },
      "source": [
        "#These libraries help to interact with the operating system and the runtime environment respectively\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "#Model/Training related libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Dataloader libraries\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TYbMM-GZk1E"
      },
      "source": [
        "Readme is part of code as comments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coyclQqC3_xW",
        "outputId": "734334ab-76d6-4532-c639-b07965d32553"
      },
      "source": [
        "#Intall Kaggle API and create kaggle directory\n",
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "!pip install -q kaggle\n",
        "#This data is used to login  into your Kaggle account\n",
        "import json\n",
        "token = {\"username\":\"virajranade\",\"key\":\"152c772ecb15eebcb68eb988aaf4e2fd\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK7fu-Iy4FVj",
        "outputId": "1fbe4498-3cad-46d6-bdcb-a303345537fd"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config set -n path -v /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "- path is now set to: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne3X7D7K4FcD",
        "outputId": "a1791e71-2cf7-461f-ad5d-28774088c3cd"
      },
      "source": [
        "#!kaggle competitions download -c hw1p2-toy-problem\n",
        "!kaggle competitions download -c idl-fall2021-hw1p2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
            " 98% 237M/241M [00:08<00:00, 20.8MB/s]\n",
            "100% 241M/241M [00:08<00:00, 31.1MB/s]\n",
            "Downloading train_labels.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
            "  0% 0.00/5.16M [00:00<?, ?B/s]\n",
            "100% 5.16M/5.16M [00:00<00:00, 171MB/s]\n",
            "Downloading train.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
            " 99% 1.90G/1.92G [00:49<00:00, 38.0MB/s]\n",
            "100% 1.92G/1.92G [00:49<00:00, 41.5MB/s]\n",
            "Downloading dev_labels.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
            "  0% 0.00/617k [00:00<?, ?B/s]\n",
            "100% 617k/617k [00:00<00:00, 88.5MB/s]\n",
            "Downloading dev.npy.zip to /content/competitions/idl-fall2021-hw1p2\n",
            " 97% 238M/246M [00:01<00:00, 229MB/s]\n",
            "100% 246M/246M [00:01<00:00, 242MB/s]\n",
            "Downloading sample.csv.zip to /content/competitions/idl-fall2021-hw1p2\n",
            "  0% 0.00/4.03M [00:00<?, ?B/s]\n",
            "100% 4.03M/4.03M [00:00<00:00, 66.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqFVpNsC4FfG",
        "outputId": "eca81d49-bc14-4627-f5d0-903f456e2e45"
      },
      "source": [
        "!unzip competitions/idl-fall2021-hw1p2/train.npy.zip\n",
        "!unzip competitions/idl-fall2021-hw1p2/train_labels.npy.zip\n",
        "!unzip competitions/idl-fall2021-hw1p2/dev.npy.zip\n",
        "!unzip competitions/idl-fall2021-hw1p2/dev_labels.npy.zip\n",
        "!unzip competitions/idl-fall2021-hw1p2/test.npy.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  competitions/idl-fall2021-hw1p2/train.npy.zip\n",
            "  inflating: train.npy               \n",
            "Archive:  competitions/idl-fall2021-hw1p2/train_labels.npy.zip\n",
            "  inflating: train_labels.npy        \n",
            "Archive:  competitions/idl-fall2021-hw1p2/dev.npy.zip\n",
            "  inflating: dev.npy                 \n",
            "Archive:  competitions/idl-fall2021-hw1p2/dev_labels.npy.zip\n",
            "  inflating: dev_labels.npy          \n",
            "Archive:  competitions/idl-fall2021-hw1p2/test.npy.zip\n",
            "  inflating: test.npy                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmKUQr8rZdfw"
      },
      "source": [
        "Here we have used vstack to create the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAfm2GoI4FiB",
        "outputId": "f3b9ace2-66b9-40c7-b856-eb7efee1cbc1"
      },
      "source": [
        "train_data = np.vstack(np.load('train.npy',allow_pickle=True))\n",
        "print(np.shape(train_data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18482968, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA6HWVjzZcrE"
      },
      "source": [
        "Similarly for val and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yHq9l-h4Fk7",
        "outputId": "fb52b85f-b48c-478e-99dc-e3a020abeeb1"
      },
      "source": [
        "test_data = np.vstack(np.load('test.npy',allow_pickle=True))\n",
        "print(np.shape(test_data))\n",
        "val_data = np.vstack(np.load('dev.npy',allow_pickle=True))\n",
        "print(np.shape(val_data))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1910012, 40)\n",
            "(1935669, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JbdB_oCZrOY"
      },
      "source": [
        "To create a set of empty labels for test_labels.\n",
        "We use test_set and create it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUbF4tw64Fns",
        "outputId": "3e4774a9-fa02-4e51-802c-3e2c9300cbd7"
      },
      "source": [
        "k=np.shape(test_data)[0]\n",
        "test_labels=[]\n",
        "\n",
        "for i in range(k):\n",
        "  c=np.shape(test_data[i])[0]\n",
        "  h=np.ones((c,))\n",
        "  test_labels.append(h)\n",
        "np.array(test_labels,dtype=object)\n",
        "print(np.shape(test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1910012, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvz6HCIi4Fqe",
        "outputId": "f5fa3b60-8b7b-4328-e702-c3bc18e6afda"
      },
      "source": [
        "train_labels=np.concatenate(np.load('train_labels.npy',allow_pickle=True))\n",
        "val_labels=np.concatenate(np.load('dev_labels.npy',allow_pickle=True))\n",
        "print(np.shape(val_data))\n",
        "print(np.shape(val_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1935669, 40)\n",
            "(1935669,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWmO1q34Ftq"
      },
      "source": [
        "class MyMLPDataset(Dataset):\n",
        "  def __init__(self,X,y,context=0):\n",
        "    self.data=X\n",
        "    self.labels=y\n",
        "    assert len(self.data)==len(self.labels)\n",
        "    self.length=len(self.labels)\n",
        "\n",
        "    self.context=context\n",
        "    self.data=np.pad(self.data,((self.context,self.context),(0,0)),mode='constant', constant_values=0).astype('float32')\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    x=self.data[index:(index+(2*self.context)+1)].flatten()\n",
        "    y=self.labels[index].astype(np.long)\n",
        "\n",
        "\n",
        "    return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fIuiIHT4Fwj"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "# Training dataloader\n",
        "train_dataset = MyMLPDataset(train_data,train_labels,context=20)\n",
        "train_args = dict(shuffle = True, batch_size = 128, num_workers=2)\n",
        "train_loader = DataLoader(train_dataset, **train_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYvhxZO54Fzl"
      },
      "source": [
        "# Validation dataloader\n",
        "val_dataset = MyMLPDataset(val_data, val_labels,context=20)\n",
        "val_args = dict(shuffle = False, batch_size = 128, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, **val_args)\n",
        "#collate_fn=MLPDataset.collate_fn-> Use this while using Index map dataset.\n",
        "### Slower but accuracy is better.\n",
        "\n",
        "#Test dataLoader\n",
        "\n",
        "test_dataset = MyMLPDataset(test_data, test_labels,context=20)\n",
        "test_args = dict(shuffle = False, batch_size = 128, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, **test_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz8LAx_N48IE",
        "outputId": "4fc4c729-7959-4b69-e5da-a84747a0fa77"
      },
      "source": [
        "for batch, (data, targets) in enumerate(test_loader):\n",
        "  print (data.shape)\n",
        "  print (targets.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1640])\n",
            "torch.Size([128, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9svmr7Ps5Aer",
        "outputId": "4bd39792-2cfa-4f0d-ff14-d9d6070337fe"
      },
      "source": [
        "for batch,(data,targets) in enumerate(train_loader):\n",
        "   print (data.shape)\n",
        "   print (targets.shape)\n",
        "   if (batch > 4):\n",
        "     break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1640])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ5XlRY4aTx1"
      },
      "source": [
        "1st attempt was same Model, except with ReLU\n",
        "After 3 Epochs I got Acc 75.1\n",
        "I needed a stronger model so I trained this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBw9PxTC5E1C"
      },
      "source": [
        "## Model Architecture definition\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    # define model elements\n",
        "    def __init__(self, size):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        # Sequential model definition: Input -> Linear -> ReLU -> Linear -> Output\n",
        "        Linear_layers=[\n",
        "                       nn.Linear(1640,4608,True),nn.BatchNorm1d(4608,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(4608,4608,True),nn.BatchNorm1d(4608,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(4608,4608,True),nn.BatchNorm1d(4608,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(4608,2304,True),nn.BatchNorm1d(2304,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(2304,1152,True),nn.BatchNorm1d(1152,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(1152,576,True),nn.BatchNorm1d(576,eps=1e-08),nn.LeakyReLU(),\n",
        "                       nn.Linear(576,72,True)]\n",
        "        self.layers = nn.Sequential(*Linear_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #torch.save(model.state_dict(), 'C:/Users/ADMIN/Desktop/Fall_21/11785/Homeworks/hw1p1')\n",
        "        # Model forward pass\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyi2GDtO5IZD",
        "outputId": "e3da5738-ef42-4ea5-9515-f612f3258663"
      },
      "source": [
        "# Model\n",
        "model = MLP([440,9216,4608,2304,1152,576,72])\n",
        "#model = MLP([32,440])\n",
        "\n",
        "# Define Criterion/ Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define Adam Optimizer\n",
        "\n",
        "## refer to TA\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda else 'cpu')\n",
        "#device=torch.device('cpu')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,[5,10])\n",
        "criterion=  nn.CrossEntropyLoss()\n",
        "model=model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=1640, out_features=4608, bias=True)\n",
            "    (1): BatchNorm1d(4608, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): Linear(in_features=4608, out_features=4608, bias=True)\n",
            "    (4): BatchNorm1d(4608, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Linear(in_features=4608, out_features=4608, bias=True)\n",
            "    (7): BatchNorm1d(4608, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.01)\n",
            "    (9): Linear(in_features=4608, out_features=2304, bias=True)\n",
            "    (10): BatchNorm1d(2304, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): LeakyReLU(negative_slope=0.01)\n",
            "    (12): Linear(in_features=2304, out_features=1152, bias=True)\n",
            "    (13): BatchNorm1d(1152, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): LeakyReLU(negative_slope=0.01)\n",
            "    (15): Linear(in_features=1152, out_features=576, bias=True)\n",
            "    (16): BatchNorm1d(576, eps=1e-08, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): LeakyReLU(negative_slope=0.01)\n",
            "    (18): Linear(in_features=576, out_features=72, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IDi8wuEagcX"
      },
      "source": [
        "In case the saved model needs to be Loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04pLT5Qe5OI6"
      },
      "source": [
        "## Load the model for testing \n",
        "## Older Model\n",
        "best_model_loc = 'drive/MyDrive/model.pth'\n",
        "checkpoint = torch.load(best_model_loc)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(checkpoint['epoch'])\n",
        "## Do not Run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG0wvpbw5VpD"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "def train_model(train_loader, model,criterion,optimizer,scheduler):\n",
        "\n",
        "  training_loss = 0\n",
        "  \n",
        "  # Set model in 'Training mode'\n",
        "  model.train()\n",
        "  \n",
        "  # enumerate mini batches\n",
        "  for batch, (data,targets) in enumerate(train_loader):\n",
        "      \n",
        "      # clear the gradients\n",
        "      optimizer.zero_grad()\n",
        "      data=data.to(device)\n",
        "      targets=targets.to(device)\n",
        "      #mode=model.to(device)\n",
        "      \n",
        "      # compute the model output\n",
        "      output = model(data)\n",
        "      \n",
        "      # calculate loss\n",
        "      loss = criterion(output,targets)\n",
        "      \n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      \n",
        "      # Update model weights\n",
        "      optimizer.step()\n",
        "\n",
        "      training_loss += loss.item()\n",
        "      \n",
        "      #end_time=time.time()\n",
        "      #print('Time for 1 iteration is',end_time-start_time)\n",
        "      #start_time=end_time\n",
        "  training_loss /= len(train_loader)\n",
        "  scheduler.step()\n",
        "  return training_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7UETJv5Ykc"
      },
      "source": [
        "def val_model(val_loader,model,criterion,optimizer):\n",
        "  size=len(val_loader.dataset)\n",
        "  num_batches=len(val_loader)\n",
        "  test_loss=0\n",
        "  correct=0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for index,(data,labels) in enumerate(val_loader):\n",
        "      data=data.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "      pred=model(data)\n",
        "      predicted_labels=pred.argmax(1)\n",
        "      loss=criterion(pred,labels)\n",
        "      test_loss +=loss.item()\n",
        "      correct +=(pred.argmax(1)==labels).type(torch.float).sum().item()\n",
        "    \n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    print(f'\\n Test Error is ',correct*100,'Accuracy', test_loss,'Average Loss')\n",
        "    return (correct,test_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgxOMmyaqj6"
      },
      "source": [
        "By the time I tested, I had only enough time for 1 epoch.\n",
        "Thus I ran only 1 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhG48Kd25cmT",
        "outputId": "c141af7e-3305-4c79-8039-d4efd733abd9"
      },
      "source": [
        "# Define number of epochs\n",
        "nepochs = 1\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,[5,10])\n",
        "#CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    #model.train()\n",
        "\n",
        "    # Train\n",
        "    epoch_start_time=time.time()\n",
        "\n",
        "    training_loss = train_model(train_loader,model,criterion,optimizer,scheduler)\n",
        "    val_acc, val_loss = val_model(val_loader, model,criterion,optimizer)\n",
        "    # enumerate mini batches\n",
        "    \n",
        "    '''\n",
        "    for i, (data,targets) in enumerate(train_loader):\n",
        "        \n",
        "        # clear the gradients\n",
        "        #optimizer.zero_grad()\n",
        "        #data=data.to(device)\n",
        "        #targets=targets.to(device)\n",
        "        # compute the model output\n",
        "        output = model(data)\n",
        "        # calculate loss\n",
        "        loss = criterion(output,targets)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # scheduler\n",
        "        \n",
        "        #torch.save(model.state_dict(), 'model_weights.pth')\n",
        "        # Print log of accuracy and loss\n",
        "        '''\n",
        "    epoch_end_time=time.time()\n",
        "    #model = model.vgg16(pretrained=True)\n",
        "    filename = str(f\"mymodel_epoch_{epoch}.pth\")\n",
        "    torch.save({'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scheduler_state_dict' : scheduler.state_dict()}, filename)\n",
        "    \n",
        "\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss),'Time required',(epoch_end_time-epoch_start_time))\n",
        "    print(\"Epoch: \"+str(epoch)+\", Val_accuracy: \"+str(val_acc)+\", Validation loss:\"+str(val_loss)+\n",
        "          \", Validation accuracy:\"+str(val_acc*100)+\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test Error is  74.962816473271 Accuracy 0.8356455934455601 Average Loss\n",
            "Epoch: 0, Training loss: 0.760509930688249 Time required 3097.6073050498962\n",
            "Epoch: 0, Val_accuracy: 0.74962816473271, Validation loss:0.8356455934455601, Validation accuracy:74.962816473271%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txNHAi955i6T"
      },
      "source": [
        "def test_model(test_loader,model):\n",
        "  #size=len(test_loader.dataset)\n",
        "  #num_batches=len(test_loader)\n",
        "  #test_loss=0\n",
        "  #correct=0\n",
        "  model.eval()\n",
        "  predictions=[]\n",
        "  with torch.no_grad():\n",
        "    for index,(X,y) in enumerate(test_loader):\n",
        "      X=X.to(device)\n",
        "      #y=y.to(device)\n",
        "\n",
        "      predicted_labels=model(X)\n",
        "      #predicted_labels=pred.argmax(1)\n",
        "      #loss=criterion(pred,y)\n",
        "      #test_loss +=loss.item()\n",
        "      #correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "      predicted_labels=predicted_labels.detach()\n",
        "      predicted_labels=predicted_labels.cpu()\n",
        "      predicted_labels=predicted_labels.numpy()\n",
        "      predicted_labels = np.argmax(predicted_labels, axis=1)\n",
        "      predicted_labels = np.reshape(predicted_labels,(-1,1))\n",
        "      predictions.append(predicted_labels)\n",
        "    #test_loss /= num_batches\n",
        "    #correct /= size\n",
        "    \n",
        "    # predictions=np.vstack(predictions)\n",
        "    #print(f'\\n Test Error is ',correct*100,'Accuracy', test_loss,'Average Loss')\n",
        "    return (predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGHk6X6zlxeh",
        "outputId": "11883e56-0cb6-4197-f948-5406d5ff0fb9"
      },
      "source": [
        "best_model_loc = '/content/mymodel_epoch_0.pth'\n",
        "checkpoint = torch.load(best_model_loc)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(checkpoint['epoch'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIHLlqSx5nXY",
        "outputId": "84972a10-8757-4161-b3dc-8a5b08b78bf4"
      },
      "source": [
        "pred = test_model(test_loader, model)\n",
        "print(len(pred))\n",
        "predictions = list(np.concatenate(pred).flat)\n",
        "ids = np.arange(len(predictions))\n",
        "len(ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1910012"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2t4Lu9WAWLS",
        "outputId": "cb1a0c41-e476-47d4-9312-490e065a433d"
      },
      "source": [
        "import pandas as pd\n",
        "my_submission_2=pd.DataFrame({'id':ids,'label':predictions})\n",
        "my_submission_2.to_csv('try_7.csv', index=False)\n",
        "!kaggle competitions submit -c idl-fall2021-hw1p2 -f 'try_6.csv' -m 'try7'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 18.5M/18.5M [00:10<00:00, 1.83MB/s]\n",
            "Successfully submitted to IDL-Fall21-HW1P2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwQHyTzxAoq8"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('try_2.csv') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}